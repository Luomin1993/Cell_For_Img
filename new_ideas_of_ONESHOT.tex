\section{反思}
对于前段时间提出的一些东西的反思,首先是那个平滑的属性拆解,消极一点说,我现在觉得它这个想法不过是把\textbf{聚类}换了一种方式表达出来,\textbf{平滑的属性拆解}想做的是:

$$\theta = \argmax_{\theta} P(Y | filter(img,\theta)=\{img_1,img_2,...,img_n\})$$

也就是通过分类效果反过来调节属性拆解的参数,是一种典型的反向误差传播.而有监督聚类比如LDA降维想做的是:使得降维后的数据点尽可能地容易被区分,LDA的思想可以用一句话概括,就是“投影后类内方差最小,类间方差最大”:

$$MAX \; J(W) = \frac{\prod\limits_{i=1}^dw_i^TS_bw_i}{\prod\limits_{i=1}^dw_i^TS_ww_i} = \prod\limits_{i=1}^d\frac{w_i^TS_bw_i}{w_i^TS_ww_i}$$

但是和平滑属性拆解也不是完全一样,因为LDA降维没有涉及到分类器和训练阶段,而是完全处于前期的数据预处理阶段.但是还是有些像.

另一个就是咱们之前想做的zero-shot learning,我看完了那些分析之后,发现我们在上周二本来打算做的"提取颜色和形状特征再进行神经网络分类实验看是否在CIFAR-100上有效果提升",已经被证实确实有效并且被做得更深入了\cite{A2} \cite{A2};所以我暂时决定没有去实现这个工作(对于这一点很抱歉),但是我深入思考了更深度的一些问题(比如真正的one-shot到底是怎么样的生理原理实现的?),现在我准备总结一下这个思考流程,不过总体来说,我还是没有思考出什么有进展的东西.

必须要说的是我觉得沿着之前的zero-shot思路做估计和他们差别不大,也不会太有进展,所以才思考得更发散.另外这次我用了很多图来辅助说明.

\section{一种zero-shot的改进版}
\subsection{学习器的构造}
刚开始我还是沿着zero-shot的思路开始思考的,所以我考虑了这么一个多分类问题:存在一个属性集合:$\{A_i\}$,还有属性集对应的描述值:$\{D_{A_i}\}$,现在首先让我们弱化标签这个概念(事实上,在zero-learning的核心思维中,标签的概念也被弱化了,取代标签的是一系列特征的值.),我们假设对一件事物的理解是建立在它的属性上的,比如说,对于CIFAR-10这个数据集,Frog(青蛙)可以有Attribute(属性)"皮肤颜色(Skin_Color)"、"腿数(Leg_Num)"、"食素(Is_Vegetarian)"这些属性标签,当我们看见这些属性标签时,就会想,噢这肯定是一个动物(所以这些属性可以认为是我们对这个事物的粗略认识).如果是Ship(船)我们可以有属性"载重量(Heavy)"、"排水量(Displacement)"、"颜色(Color)"等等,当我们看见这些属性标签时,就会想,噢这肯定是一个交通工具.

所以存在一个属性集合:$\{A_i\}$,这里面的一些属性足够让我们认识到,这个东西大概是个什么类别,进而"皮肤颜色(Skin_Color)=5"、"腿数(Leg_Num)=4"、"食素(Is_Vegetarian)=1"这些更高层的细节(zero-shot直接做到了这层)才会定性这个物体到底具体是啥(哪种动物).

所以需要两层映射来学习这种分类,第一层,根据输入确定这个object有哪些属性,第二层,带着这些选出来的属性再细致地学习这些属性的对应值,最终得到的属性值集合$\{D_{A_i}\}$有足够的表达力来解释这个图片的类别:

$$F(X):X \rightarrow A' \in \{A_i\}$$
$$G(X,A'): X,A' \rightarrow \{D_{A_i}\}$$

也就是说我希望第一层映射可以通过输入学习到该样本$X$带有哪些属性(也就是大概是个什么物体:动物或者交通工具或者其他物体),再通过第二个映射学习到该样本每个属性对应的值(也就是具体是什么动物?).

还有一个关键的思路就是,我们可以把特征提取这一步看做人体视觉系统对图像的\textbf{感知},比如对颜色的感知可以看作是颜色特征提取\cite{A5},对形状的感知可以看作是外形轮廓特征提取\cite{A6}.那么在第一层映射前就是提取一系列的特征向量集合:

$$\{\hat{X}_i\} = filter(X)$$

现在对图像的\textbf{感知}之后就是对图像的\textbf{认知},即之后的映射方法.

\subsection{这种方法的实行方式和缺陷}
由于CIFAR-10的物体种类不多,所以编写程序将其转化为这个问题可以使用的数据集是比较容易的,我编写了一个程序来转化这些数据.

我对这种方法仍然觉得不满意的地方是：它能做到比传统的zero-shot方法利用更少的样本来学习吗?如果要实现这个架构,我觉得恐怕还是不得不用神经网络,那是否仍然需要大量的训练集?如果还是使用随机梯度下降等方法来优化,那么相对传统问题的优势何在?这么一想感觉其实并没有多大改进.




\section{一种从生物学实验想到的学习模型}
\subsection{这种模型的构造}
这是我后来发现的另一篇生物学论文:<<白鼠基于观察的学习模式...>> \cite{A3}想到的一些东西;在这之前关于替代神经网络这种不太符合生理真实原理的思考持续了很久,大概两天,总之最后思考出来的想法是,生物之所以能够高效地学习(比如只需要一张图像来识别物体而不是很多张),不是靠梯度下降,而是依靠\textbf{模仿}.

比如在谈到狗时,我们脑子会浮现出一只狗的图像,那是一只现实中不存在的狗,那是我们的大脑\textbf{模拟}出来的,这和我们之前谈到的图景也有一定的联系.

\begin{figure}[H]
\centering        
\includegraphics[height=5cm,width=9.4cm]{learn_2.jpg}
\caption{The CAG of "Active people often send the friend-circle photos because of small things." and "Lv is an active man in the friend-circle."}      
\end{figure}

这时候标签就不再是标签了,而是需要被编码的其中一个普通的量.

$$X \rightarrow \hat{X} \rightarrow X'$$

其中$\hat{X}$是样本$X$在特征空间内的编码,它是不可解释但是可度量的,\textbf{不可解释}是指不能直观解释的特征向量,\textbf{可度量}是指相似的样本在这个空间里距离相近.而第二层隐射构造的$X'$则是样本$X$在大脑中的镜像,也就是我们之前讨论的图景.


\subsection{这种方法的实行和缺陷}
这样一看感觉所要构造的镜像(图景)$X'$是我们的模型自己对样本$X$生成模拟的,模拟得越像(即$min||X-X'||$)说明模型更好地理解了样本.

但是,这是否和GAN(对抗生成网络)有些雷同?难道绕了一圈又回到了别人做过的东西?事实上,虽然感觉差不多,但是还是有一些区别,比如对抗神经网络是通过自编码器由随机采样的因子生成的样本.而此处这个模型是根据特征生成的(我不确定是否有其他类型的GAN这样做了).而且我也没打算一定要用神经网络.

如果使用神经网络那么又面临大样本的要求,就又要面临优势何在这个问题了.

\section{一种更仿生的模型}
我不得不承认这个模型的构想有点民科,我从蚁群算法和PSO粒子群算法这些集体智慧算法想到,也许和单个蚁群算法中的蚂蚁和粒子群算法中的粒子一样,单个神经元也是极其不具备智能的单元,但是某种自组织模式导致其群体,神经群体(和神经网络模型不一样,这里我想象的不是一个分层的模型)有一种自适应性来应对复杂的输入模式.

